{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperPerimeter Tuning for the above model...\n",
    "## pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "from keras.src.models import Sequential \n",
    "from keras.src.layers import Dense, Dropout, Input\n",
    "from keras_tuner import RandomSearch \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from keras.src.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.src.utils import to_categorical\n",
    "import pandas as pd \n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayku\\AppData\\Local\\Temp\\ipykernel_19284\\3688986210.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['NObeyesdad'] = df['NObeyesdad'].replace(target_category_rank)\n"
     ]
    }
   ],
   "source": [
    "## Spliting data into train and test data\n",
    "\n",
    "## Read the raw data from sql table.\n",
    "\n",
    "conn = sql.connect('../DataBase/TrainingData.db')\n",
    "query=\"SELECT * FROM HealthData\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "df = df.dropna(subset=['NObeyesdad'])  # Remove rows where the target is missing\n",
    "\n",
    "\n",
    "## Defining the numerical, ordinal and nominal features.\n",
    "num_cols = [col for col in df.columns if df[col].dtype != 'object']\n",
    "\n",
    "nominal_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC', 'MTRANS']\n",
    "\n",
    "ordinal_cols = [ 'CALC', 'CAEC']\n",
    "\n",
    "target_col = ['NObeyesdad']\n",
    "\n",
    "## Building pipeline for data transformation\n",
    "\n",
    "# For numerical features: impute with median and scale the data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For nominal features: impute with most frequent and encoded respectively \n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OneHotEncoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# For nordinal features: impute with most frequent and encoded respectively \n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OrdinalEncoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "\n",
    "# ColumnTransformer to apply different transformations to different columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_cols),\n",
    "        ('nom', nominal_transformer, nominal_cols),\n",
    "        ('ord', ordinal_transformer, ordinal_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "target_category_rank = {\n",
    "    'Normal_Weight': 1,\n",
    "    'Insufficient_Weight': 2,\n",
    "    'Overweight_Level_I': 3,\n",
    "    'Overweight_Level_II': 4,\n",
    "    'Obesity_Type_I': 5,\n",
    "    'Obesity_Type_II': 6,\n",
    "    'Obesity_Type_III': 7\n",
    "}\n",
    "\n",
    "df['NObeyesdad'] = df['NObeyesdad'].replace(target_category_rank)\n",
    "# Fit the preprocessor on the training data\n",
    "# Fit and transform the features\n",
    "\n",
    "df_transformed = preprocessor.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>SMOKE_yes</th>\n",
       "      <th>SCC_no</th>\n",
       "      <th>SCC_yes</th>\n",
       "      <th>MTRANS_Automobile</th>\n",
       "      <th>MTRANS_Bike</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "      <th>CALC</th>\n",
       "      <th>CAEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-0.875589</td>\n",
       "      <td>-0.862558</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>0.561997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-1.947599</td>\n",
       "      <td>-1.168077</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>1.618759</td>\n",
       "      <td>2.339750</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.206889</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>-0.366090</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>0.561997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423582</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.364507</td>\n",
       "      <td>0.839627</td>\n",
       "      <td>0.122740</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>-2.167023</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age    Height    Weight      FCVC       NCP      CH2O       FAF  \\\n",
       "0 -0.522124 -0.875589 -0.862558 -0.785019  0.404153 -0.013073 -1.188039   \n",
       "1 -0.522124 -1.947599 -1.168077  1.088342  0.404153  1.618759  2.339750   \n",
       "2 -0.206889  1.054029 -0.366090 -0.785019  0.404153 -0.013073  1.163820   \n",
       "3  0.423582  1.054029  0.015808  1.088342  0.404153 -0.013073  1.163820   \n",
       "4 -0.364507  0.839627  0.122740 -0.785019 -2.167023 -0.013073 -1.188039   \n",
       "\n",
       "        TUE  Gender_Female  Gender_Male  ...  SMOKE_yes  SCC_no  SCC_yes  \\\n",
       "0  0.561997            1.0          0.0  ...        0.0     1.0      0.0   \n",
       "1 -1.080625            1.0          0.0  ...        1.0     0.0      1.0   \n",
       "2  0.561997            0.0          1.0  ...        0.0     1.0      0.0   \n",
       "3 -1.080625            0.0          1.0  ...        0.0     1.0      0.0   \n",
       "4 -1.080625            0.0          1.0  ...        0.0     1.0      0.0   \n",
       "\n",
       "   MTRANS_Automobile  MTRANS_Bike  MTRANS_Motorbike  \\\n",
       "0                0.0          0.0               0.0   \n",
       "1                0.0          0.0               0.0   \n",
       "2                0.0          0.0               0.0   \n",
       "3                0.0          0.0               0.0   \n",
       "4                0.0          0.0               0.0   \n",
       "\n",
       "   MTRANS_Public_Transportation  MTRANS_Walking  CALC  CAEC  \n",
       "0                           1.0             0.0   3.0   2.0  \n",
       "1                           1.0             0.0   2.0   2.0  \n",
       "2                           1.0             0.0   1.0   2.0  \n",
       "3                           0.0             1.0   1.0   2.0  \n",
       "4                           1.0             0.0   2.0   2.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract feature names from the transformers\n",
    "# For numerical features, the feature names remain the same\n",
    "num_feature_names = num_cols\n",
    "\n",
    "# For nominal features, extract feature names from OneHotEncoder\n",
    "nominal_feature_names = preprocessor.transformers_[1][1].named_steps['OneHotEncoder'].get_feature_names_out(nominal_cols)\n",
    "\n",
    "# For ordinal features, the feature names remain the same\n",
    "ordinal_feature_names = ordinal_cols\n",
    "\n",
    "# Combine all feature names\n",
    "inputs_feature_names = num_feature_names + nominal_feature_names.tolist() + ordinal_feature_names\n",
    "\n",
    "\n",
    "input_df = pd.DataFrame(df_transformed, columns=inputs_feature_names)\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=input_df\n",
    "y=df['NObeyesdad']\n",
    "x_train,  x_test, y_train , y_test =train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_hp_cat = to_categorical(y_train)\n",
    "y_test_hp_cat = to_categorical(y_test)\n",
    "\n",
    "y_test_hp_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model-building function \n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer with tunable number of neurone\n",
    "    model.add(Input(shape=(x_train.shape[1],)))\n",
    "    model.add(Dense(units=hp.Int('units_input', min_value=32, max_value=256, step=32),\n",
    "                    activation='relu'))\n",
    "    \n",
    "    # first hidden layer with tunable units and dropout\n",
    "    model.add(Dense(units=hp.Int('units_hidden1', min_value=64, max_value=256, step=32), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_hidden1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # second hidden layer\n",
    "    model.add(Dense(units=hp.Int('unit_hidden2', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('unit_dropout2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # third hidden layer \n",
    "    model.add(Dense(units=hp.Int('unit_hidden3', min_value=16, max_value=64, step=32), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('unit_dropout3', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(y_train_hp_cat.shape[1], activation='softmax'))\n",
    "    \n",
    "    # Compie the model with a tunable learning rate\n",
    "    model.compile(optimizer=Adam( learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the tuner \n",
    "\n",
    "tuner = RandomSearch(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_trials=5,\n",
    "                     executions_per_trial=3,\n",
    "                     directory='hyperparameter_tuning',\n",
    "                     project_name='Obesity Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 17s]\n",
      "val_accuracy: 0.5670611262321472\n",
      "\n",
      "Best val_accuracy So Far: 0.9773175319035848\n",
      "Total elapsed time: 00h 06m 25s\n"
     ]
    }
   ],
   "source": [
    "## Start the search using your training data and validation data.\n",
    "\n",
    "tuner.search(x_train, y_train_hp_cat, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'units_input': 32, 'units_hidden1': 224, 'dropout_hidden1': 0.2, 'unit_hidden2': 32, 'unit_dropout2': 0.4, 'unit_hidden3': 48, 'unit_dropout3': 0.4, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\Obesity_venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "## Selecting the best model.\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\", best_hyperparameters.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.1972\n",
      "Test accuracy of the best model: 0.95\n"
     ]
    }
   ],
   "source": [
    "## evaluate on test data\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test_hp_cat)\n",
    "print(f\"Test accuracy of the best model: {test_accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Obesity_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
